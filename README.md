# Logo-2K-

ProPos:
    现有的深度聚类方法依赖于对比和非对比表征学习来完成下游聚类任务。基于对比的方法由于使用负样本不可避免地导致类别冲突，而基于非对比的方法不使用负样本，但不均匀的表征可能会导致聚类崩溃。本文提出了一种新的具有 prototype scattering 和 positive sampling 的端到端深度聚类方法来充分利用这两种方法的优势，称为ProPos。
    具体而言，首先最大化簇与簇之间的距离，称为 prototype scattering loss，这促进了表征均匀分布在超球上，即PSL类似于常规的对比损失，但簇之间必是彼此的负例，因此解决了类别冲突的问题。其次，将样本的一个数据增强与另一个增强的近邻对齐，以提高簇内紧凑性，称为 positive sampling alignment。即通过高斯分布建模表征，从表征空间采样并假设为正例，与另一个试图对齐，这样尽管不能保证从数据集中选出的负样本是真正的负例，但可以肯定采样出的领域样本相对于另一个试图是属于同一类的正例。最后使用EM框架来优化ProPos，其中E步为对表征进行K-means聚类以得到聚类分配的后验概率，即每个epoch之后在表征上进行k-means获得的伪标签，这用于PSL。M步为优化ProPos提出的两个损失函数。ProPos 的优点是避免了类别冲突、均匀的表征、簇间可分离以及簇内紧凑。通过在端到端的EM框架中优化 ProPos，在大量数据集上取得了优异的性能。
